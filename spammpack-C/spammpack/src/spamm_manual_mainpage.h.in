/** @file spamm.h */

/** \mainpage SpAMM - Overview
 *
 * \brief The Sparse Approximate Matrix Multiply (SpAMM) library.
 *
 * The public functions of this library are declared in:
 *
 * - spamm.h
 * - spamm_config.h
 * - spamm_errno.h
 * - spamm_error.h
 * - spamm_general.h
 * - spamm_hashtable.h
 * - spamm_kernel.h
 * - spamm_list.h
 * - spamm_timer.h
 * - spamm_types.h
 *
 * The documentation is organized into the following chapters:
 *
 * - \subpage spamm_examples "Examples"
 * - \subpage spamm_introduction "Introduction"
 * - \subpage spamm_algorithm "Algorithm"
 * - \subpage spamm_milestones "Future Milestones"
 * - \subpage spamm_design_goals "SpAMM Design Goals"
 * - \subpage spamm_performance "SpAMM Performance"
 * - \subpage spamm_matrix "Matrix Data Structure"
 *
 * \version @PACKAGE_VERSION_STRING@ ( @GIT_COMMIT@ )
 *
 * \date Generated on @TIMESTAMP@
 *
 * \copyright
 * This code is part of the FreeON suite of programs for linear scaling
 * electronic structure theory and ab initio molecular dynamics.
 *
 * \copyright
 * Copyright (2004). The Regents of the University of California. This
 * material was produced under U.S. Government contract W-7405-ENG-36
 * for Los Alamos National Laboratory, which is operated by the University
 * of California for the U.S. Department of Energy. The U.S. Government has
 * rights to use, reproduce, and distribute this software.  NEITHER THE
 * GOVERNMENT NOR THE UNIVERSITY MAKES ANY WARRANTY, EXPRESS OR IMPLIED,
 * OR ASSUMES ANY LIABILITY FOR THE USE OF THIS SOFTWARE.
 *
 * \copyright
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by the
 * Free Software Foundation; either version 3 of the License, or (at your
 * option) any later version. Accordingly, this program is distributed in
 * the hope that it will be useful, but WITHOUT ANY WARRANTY; without even
 * the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
 * PURPOSE. See the GNU General Public License at www.gnu.org for details.
 *
 * \copyright
 * While you may do as you like with this software, the GNU license requires
 * that you clearly mark derivative software.  In addition, you are encouraged
 * to return derivative works to the FreeON group for review, and possible
 * dissemination in future releases.
 *
 * \copyright
 * Los Alamos National Laboratory (LA-CC 01-2; LA-CC-04-086)
 *
 * \author Nicolas Bock <nicolasbock@freeon.org>
 * \author Matt Challacombe <matt.challacombe@freeon.org>
 */

/** \page spamm_examples SpAMM - Examples
 *
 * Here a short example program in C that demonstrates how to multiply two
 * matrices with the library.
 *
 * \code
 * #include <spamm.h>
 *
 * int
 * main ()
 * {
 * }
 * \endcode
 *
 */

/** \page spamm_introduction SpAMM - Introduction
 *
 * A spamm_t matrix is defined as an \f$ N \f$-tree on the 2-dimensional
 * matrix elements. The matrix elements at the lowest level are stored in
 * dense matrix blocks. The matrix is padded with zeros so that the tree depth
 * \f$ d \f$ is integer according to
 *
 * \f[
 * M = M_{\mathrm{block}} M_{\mathrm{child}}^d
 * \]
 * \[
 * N = N_{\mathrm{block}} N_{\mathrm{child}}^d
 * \f]
 *
 * where \f$ M \f$ (\f$ N \f$) is the number of rows (columns) of the matrix,
 * \f$ M_{\mathrm{block}} \f$ (\f$ N_{\mathrm{block}} \f$) is the number of
 * rows (columns) of the dense matrix blocks at the lowest tree level, \f$
 * M_{\mathrm{child}} \f$ (\f$ N_{\mathrm{child}} \f$) is the number of rows
 * (columns) of the children nodes per node in the matrix tree, and \f$ d \f$
 * is the depth of the tree. This means that the matrix tree is a quadtree for
 * \f$ M_{\mathrm{child}} = N_{\mathrm{child}} = 2 \f$.
 *
 * More details can be found in the \ref spamm_algorithm "Algorithm" section
 * of this manual.
 */

/** \page spamm_algorithm SpAMM - Algorithm
 *
 * The multiplication is divided into a symbolic part and a multiplication
 * part. The symbolic part constructs the matrix product convolution such that
 * it creates up to N copies of each \f$ C_{ij} \f$ block to allow for full
 * parallelism in the multiplication part. This data redundancy circumvents
 * possible race conditions in \f$ C \f$ and we can take full advantage of SMP
 * in the multiply. The multiplication part then works through the convolution
 * stream and parallelizes multiplies if possible (i.e. if we are running on
 * SMP). In a final stage, the redundant \f$ C \f$ blocks are summed and the
 * final \f$ C \f$ matrix is constructed.
 *
 * -# Symbolic: Construct convolution with redundant \f$ C_{ij} \f$ blocks.
 * -# Multiplication: Work through convolution and parallelize work as much as
 *  possible.
 * -# Sum: Sum redundant \f$ C_{ij} \f$ blocks to construct final \f$ C \f$
 *   matrix.
 */

/** \page spamm_milestones SpAMM - Milestones
 *
 * This chapter summarizes achieved and planned future milestones.
 *
 * \section spamm_sec_future_milestones Future Milestones
 *
 * - Clean up spamm_multiply.
 * - Benchmark for now with standard lapack (netlib) _not_ using SSE.
 * - Check proper ordering of matrix elements and multiply.
 *
 * \section spamm_sec_achieved_milestones Achieved Milestones
 *
 * - 2010-06-18: Implemented spamm_tree_pack(). Added test for this function.
 * - 2010-06-18: Implemented linear quadtree support in spamm_add().
 * - 2010-06-23: Implemented linear quadtree support in spamm_multiply().
 * - 2010-06-24: Implemented full multiply including beta != 1.0.
 * - 2010-06-25: Added more testcases and organized them.
 * - 2010-07-02: Consolidated 3 benchmark testcase: dense, diagonal, and
 *   column_row. All are combined in the multiply benchmark.
 */

/** \page spamm_design_goals SpAMM - Design Goals
 *
 * - Serial execution
 *   - Use standard gemm kernel from BLAS (Goto)
 *   - Use small self-made kernel: SpAMM kernel (for instance on 9x9 blocks
 *     with Peano curve ordering)
 * - SMP execution
 *   - Use standard gemm kernel (Goto)
 *   - Use SpAMM kernel
 * - GPU execution
 * - Combined execution with work queue. In this case we put the multiply
 *   curve in a queue and allow for SMP and GPU execution. Chunks are
 *   processed to involve all components.
 *
 * See also section \ref spamm_milestones "Milestones" for a detailed
 * break-down of these goals.
 */

/** \page spamm_performance SpAMM - Performance Results
 *
 * Performance \f$ p \f$ is measured by measuring walltime (or user time from
 * getrusage()) \f$ t \f$ as
 *
 * \f[
 * p = M \times N \times ( 2 K + 1 ) / t
 * \f]
 *
 * because the matrix product
 *
 * \f[
 * C_{ij} = \beta C_{ij} + \sum_{k} \alpha A_{ik} B_{kj}
 * \f]
 *
 * involves 2 multiply and 1 add operation per term in the sum over \f$ k \f$.
 * There are \f$ M \times N \f$ elements in matrix \f$ C \f$. The first term
 * \f$ \beta C_{ij} \f$ contributes \f$ M \times N \f$ multiplies.
 *
 * Open questions:
 *
 * - How close can the stream multiply performance be pushed to match GotoBLAS
 *   large N performance? If stream is slower, why? Understand better what
 *   Goto does to make his multiply fast.
 *
 * - The 4x4 SSE kernel in <tt>prototype/kernel_comparison</tt> is performing
 *   at around 80\% of Goto neglecting cache misses. Presumably one has to
 *   stream through more data to achieve higher throughput than this. We are
 *   now integrating this SSE kernel into a stream multiply that will achieve
 *   this.
 */

/** \page spamm_matrix SpAMM - Matrix Data Structure
 *
 * Conceptually, the matrix is stored in a k-d tree data structure. For
 * performance, the actual data structure is a hybrid. Matrices are created by
 * calling spamm_new().
 *
 * The top tiers of the matrix are stored in hierarchical k-d format. If
 * spamm_matrix_t::linear_tier <= spamm_matrix_t::contiguous_tier, then the
 * tree will switch to linear quadtree format at tier ==
 * spamm_matrix_t::linear_tier. If spamm_matrix_t::contiguous_tier <
 * spamm_matrix_t::linear_tier, then the tree will be stored completely in
 * hierarhical quadtree format and at tier == spamm_matrix_t::contiguous_tier,
 * dense column-major submatrix blocks will be stored and the spamm condition
 * applied.
 *
 * The matrix dimensions \f$ M \f$ and \f$ N \f$ are padded to powers of 2 so
 * that recursive bisection is possible. The lowest \f$ N_{cont} \f$ tiers are
 * stored in contiguously allocated memory. The multiply uses a dense kernel
 * to operate on these contiguous blocks. Within the contiguous blocks, the
 * matrix elements are organized in submatrix blocks of size \f$ N_{kernel}
 * \f$, which means that the computational kernel will apply the spamm
 * condition to those submatrices.
 *
 * \code
 * struct spamm_matrix_chunk_t
 * {
 *   uint32         number_dimensions;
 *   uint32         N_lower[number_dimensions];
 *   uint32         N_upper[number_dimensions];
 *   spamm_float_t  A[N_contiguous*N_contiguous];
 *   spamm_float_t  A_transpose[N_contiguous*N_contiguous];
 *   spamm_float_t  A_dilated[N_contiguos*N_contiguous];
 *   spamm_float_t  norm[]
 *   spamm_float_t  norm2[]
 * };
 * \endcode
 *
 * \image html Matrix_Structure.png "The layout of the spamm_matrix_t data structure."
 */
